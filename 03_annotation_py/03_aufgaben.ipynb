{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungsaufgaben 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Aufgabe 1 (eigenen Sentence-Segmenter erstellen)\n",
    "\n",
    "Satzsegmentierung (End-of-Sentence-Detection) kann als binäre Klassifikation verstanden werden (s. https://www.nltk.org/book/ch06.html#sentence-segmentation), die für jedes Token in einem Korpus entscheidet, ob es ein ***sentence boundary token*** ist oder nicht. Dies ist genauer eine **Sequenzklassifikation**, da die Entscheidung abhängt vom ***Kontext der Punktuationszeichen*** (z.B. `['Mr', '.']`).\n",
    "\n",
    "\n",
    "Erzeugen Sie einen ***(1) regelbasierten*** sowie einen ***(2) auf Satz-Segmentationsdaten der Penn-Treebank trainierten*** **Punktuationsklassifikator zur Satzsegmentierung**. \n",
    "\n",
    "Input soll eine Wordliste mit einer einfachen Tokenisierung sein, wie in folgendem englischen Beispielsatz, mit dem Sie Ihre Klassifikatoren auch testen sollen.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"You hear that Mr. Anderson? That is the sound of inevitability. Good-bye, Mr. Anderson! END\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', 'hear', 'that', 'Mr', '.', 'Anderson', '?', 'That', 'is', 'the', 'sound', 'of', 'inevitability', '.', 'Good', '-', 'bye', ',', 'Mr', '.', 'Anderson', '!', 'END']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "test_words = re.findall(r'\\w+|[^\\w\\s]+', text)  #entspricht nltk.wordpunct_tokenize\n",
    "print(test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Erklärung zum wordpunct_tokenize-REGEXP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', 'hear', 'that', 'Mr', 'Anderson', 'That', 'is', 'the', 'sound', 'of', 'inevitability', 'Good', 'bye', 'Mr', 'Anderson', 'END']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r'\\w+', text)) #findet alle Wörter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '?', '.', '-', ',', '.', '!']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r'[^\\w\\s]+', text)) #findet alle Punktuationszeichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', 'hear', 'that', 'Mr.', 'Anderson?', 'That', 'is', 'the', 'sound', 'of', 'inevitability.', 'Good-bye,', 'Mr.', 'Anderson!', 'END']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r'[^\\s]+', text)) #\\s matches whitespace characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1a (Rule-based Sentence Segmentation)\n",
    "\n",
    "\n",
    "Erstellen Sie einen einfachen regelbasierten Punctuation Tagger, der eine Liste von Wort- und Punktuationstokens in eine Liste von entsprechenden Satz-Tokenlisten auftrennt. Orientieren Sie sich dabei an https://en.wikipedia.org/wiki/Sentence_boundary_disambiguation:\n",
    "\n",
    ">   (a) If it's a period, it ends a sentence.<br>\n",
    "    (b) If the preceding token is in the hand-compiled list of abbreviations, then it doesn't end a sentence.<br>\n",
    "    (c) If the next token is capitalized, then it ends a sentence.        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sentences_rule_based(words):\n",
    "    sent_list = []\n",
    "    sent = []\n",
    "    for index,token in enumerate(words):\n",
    "        sent.append(token)\n",
    "        if token in '.?!' and words[index-1] not in [\"Mr\", \"Mrs\", \"Ms\", \"Dr\"] and words[index+1][0].isupper():\n",
    "            sent_list.append(sent)\n",
    "            sent = []\n",
    "    return sent_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['You', 'hear', 'that', 'Mr', '.', 'Anderson', '?'],\n",
       " ['That', 'is', 'the', 'sound', 'of', 'inevitability', '.'],\n",
       " ['Good', '-', 'bye', ',', 'Mr', '.', 'Anderson', '!']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_sentences_rule_based(test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1b (Supervised Sentence Segmentation)\n",
    "\n",
    "Trainieren Sie einen Punctuation Classifier mit Hilfe der Daten zur Satzsegmentierung der Penn-Treebank. Orientieren Sie sich dabei am Vorgehen in https://www.nltk.org/book/ch06.html#sentence-segmentation:\n",
    "\n",
    "- extract features for possible sentence-boundary tokens\n",
    "- learn mapping from feature-representations to binary end-of-sentence classes (boundary yes/no) \n",
    "- training data: corpus with annotation of sentence boundaries (e.g. treebanks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank # Sample of Penn Treebank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use Penn Treebank as Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first step is to obtain some data that has already been segmented into sentences \n",
    "#and convert it into a form that is suitable for extracting features:\n",
    "sents = nltk.corpus.treebank_raw.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['.', 'START'], ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov', '.', '29', '.'], ['Mr', '.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N', '.', 'V', '.,', 'the', 'Dutch', 'publishing', 'group', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(sents[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, tokens is a merged list of tokens from the individual sentences, \n",
    "#and boundaries is a set containing the indexes of all sentence-boundary tokens. \n",
    "tokens = []\n",
    "boundaries = set()\n",
    "offset = 0\n",
    "for sent in sents:\n",
    "    tokens.extend(sent)\n",
    "    offset += len(sent)\n",
    "    boundaries.add(offset-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '.'),\n",
       " (1, 'START'),\n",
       " (2, 'Pierre'),\n",
       " (3, 'Vinken'),\n",
       " (4, ','),\n",
       " (5, '61'),\n",
       " (6, 'years'),\n",
       " (7, 'old'),\n",
       " (8, ','),\n",
       " (9, 'will'),\n",
       " (10, 'join'),\n",
       " (11, 'the'),\n",
       " (12, 'board'),\n",
       " (13, 'as'),\n",
       " (14, 'a'),\n",
       " (15, 'nonexecutive'),\n",
       " (16, 'director'),\n",
       " (17, 'Nov'),\n",
       " (18, '.'),\n",
       " (19, '29'),\n",
       " (20, '.'),\n",
       " (21, 'Mr'),\n",
       " (22, '.'),\n",
       " (23, 'Vinken'),\n",
       " (24, 'is'),\n",
       " (25, 'chairman'),\n",
       " (26, 'of'),\n",
       " (27, 'Elsevier'),\n",
       " (28, 'N'),\n",
       " (29, '.'),\n",
       " (30, 'V'),\n",
       " (31, '.,'),\n",
       " (32, 'the'),\n",
       " (33, 'Dutch'),\n",
       " (34, 'publishing'),\n",
       " (35, 'group'),\n",
       " (36, '.'),\n",
       " (37, '.'),\n",
       " (38, 'START'),\n",
       " (39, 'Rudolph')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(index, token) for index,token in enumerate(tokens[0:40])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 20, 36, 38]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(boundaries))[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Feature-Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we need to specify the features of the data that will be used \n",
    "#in order to decide whether punctuation indicates a sentence-boundary:\n",
    "def punct_features(tokens, i):\n",
    "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
    "            'prev-word': tokens[i-1].lower(),\n",
    "            'punct': tokens[i],\n",
    "            'prev-word-is-one-char': len(tokens[i-1]) == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on this feature extractor, we can create a list of labeled featuresets \n",
    "#by selecting all the punctuation tokens, and tagging whether they are boundary tokens or not:\n",
    "featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
    "    for i in range(1, len(tokens)-1)\n",
    "    if tokens[i] in '.?!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'next-word-capitalized': False,\n",
       "   'prev-word': 'nov',\n",
       "   'prev-word-is-one-char': False,\n",
       "   'punct': '.'},\n",
       "  False),\n",
       " ({'next-word-capitalized': True,\n",
       "   'prev-word': '29',\n",
       "   'prev-word-is-one-char': False,\n",
       "   'punct': '.'},\n",
       "  True),\n",
       " ({'next-word-capitalized': True,\n",
       "   'prev-word': 'mr',\n",
       "   'prev-word-is-one-char': False,\n",
       "   'punct': '.'},\n",
       "  False),\n",
       " ({'next-word-capitalized': True,\n",
       "   'prev-word': 'n',\n",
       "   'prev-word-is-one-char': True,\n",
       "   'punct': '.'},\n",
       "  False),\n",
       " ({'next-word-capitalized': False,\n",
       "   'prev-word': 'group',\n",
       "   'prev-word-is-one-char': False,\n",
       "   'punct': '.'},\n",
       "  True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Train Simple Probabilistic Classifier (Naive Bayes):\n",
    "\n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936026936026936"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using these featuresets, we can train and evaluate a punctuation classifier:\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language Toolkit: code_classification_based_segmenter\n",
    "\n",
    "def segment_sentences(words):\n",
    "    start = 0\n",
    "    sents = []\n",
    "    for i, word in enumerate(words):\n",
    "        if word in '.?!' and classifier.classify(punct_features(words, i)) == True:\n",
    "            sents.append(words[start:i+1])\n",
    "            start = i+1\n",
    "    if start < len(words):\n",
    "        sents.append(words[start:])\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', 'hear', 'that', 'Mr', '.', 'Anderson', '?', 'That', 'is', 'the', 'sound', 'of', 'inevitability', '.', 'Good', '-', 'bye', ',', 'Mr', '.', 'Anderson', '!', 'END']\n"
     ]
    }
   ],
   "source": [
    "print(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['You', 'hear', 'that', 'Mr', '.', 'Anderson', '?'],\n",
       " ['That', 'is', 'the', 'sound', 'of', 'inevitability', '.'],\n",
       " ['Good', '-', 'bye', ',', 'Mr', '.', 'Anderson', '!'],\n",
       " ['END']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_sentences(test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2 (Korpusannotation mit stanza)\n",
    "\n",
    "Annotieren Sie den Text in `wahlverwandschaften.txt` nach morphologischen, syntaktischen und semantischen Kategorien mit Hilfe der deutschen stanza-Modelle.\n",
    "\n",
    "Verwenden Sie dabei auch die CoNLL-Utilities von stanza für eine Transformation eines Dependency-analysierten Satzes in das CoNLL-Format, um es als NLTK-Dependency-Tree-Objekt einzulesen und zu plotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "#stanza.download('de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a: morphologische Analyse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 14:05:27 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "=======================\n",
      "\n",
      "2022-06-02 14:05:27 INFO: Use device: cpu\n",
      "2022-06-02 14:05:27 INFO: Loading: tokenize\n",
      "2022-06-02 14:05:27 INFO: Loading: mwt\n",
      "2022-06-02 14:05:27 INFO: Loading: pos\n",
      "2022-06-02 14:05:28 INFO: Loading: lemma\n",
      "2022-06-02 14:05:28 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "text = open('wahlverwandschaften.txt').read()\n",
    "nlp = stanza.Pipeline(lang='de', processors='tokenize, mwt, lemma, pos')\n",
    "doc = nlp(text)#[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\n",
       "   {\n",
       "     \"id\": 1,\n",
       "     \"text\": \"Die\",\n",
       "     \"lemma\": \"der\",\n",
       "     \"upos\": \"DET\",\n",
       "     \"xpos\": \"ART\",\n",
       "     \"feats\": \"Case=Nom|Definite=Def|Gender=Fem|Number=Plur|PronType=Art\",\n",
       "     \"start_char\": 0,\n",
       "     \"end_char\": 3\n",
       "   },\n",
       "   {\n",
       "     \"id\": 2,\n",
       "     \"text\": \"Wahlverwandtschaften\",\n",
       "     \"lemma\": \"Wahlverwandtschaft\",\n",
       "     \"upos\": \"NOUN\",\n",
       "     \"xpos\": \"NN\",\n",
       "     \"feats\": \"Case=Nom|Gender=Fem|Number=Plur\",\n",
       "     \"start_char\": 4,\n",
       "     \"end_char\": 24\n",
       "   }\n",
       " ]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sein Geschäft war eben vollendet ;\n"
     ]
    }
   ],
   "source": [
    "print(*[f'{word.text}' for sent in doc.sentences[6:7] for word in sent.words], sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: Sein \tlemma: sein\tupos: DET\txpos: PPOSAT\tfeats: Case=Nom|Gender=Neut|Gender[psor]=Masc,Neut|Number=Sing|Number[psor]=Sing|Person=3|Poss=Yes|PronType=Prs\n",
      "word: Geschäft \tlemma: Geschäft\tupos: NOUN\txpos: NN\tfeats: Case=Nom|Gender=Neut|Number=Sing\n",
      "word: war \tlemma: sein\tupos: AUX\txpos: VAFIN\tfeats: Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\n",
      "word: eben \tlemma: eben\tupos: ADV\txpos: ADV\tfeats: _\n",
      "word: vollendet \tlemma: vollenden\tupos: ADJ\txpos: VVPP\tfeats: VerbForm=Part\n",
      "word: ; \tlemma: ;\tupos: PUNCT\txpos: $.\tfeats: _\n"
     ]
    }
   ],
   "source": [
    "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}\\tupos: {word.upos}\\txpos: {word.xpos}\\tfeats: {word.feats if word.feats else \"_\"}' for sent in doc.sentences[6:7] for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b: Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 14:05:43 WARNING: Language de package default expects mwt, which has been added\n",
      "2022-06-02 14:05:43 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| sentiment | sb10k   |\n",
      "=======================\n",
      "\n",
      "2022-06-02 14:05:43 INFO: Use device: cpu\n",
      "2022-06-02 14:05:43 INFO: Loading: tokenize\n",
      "2022-06-02 14:05:43 INFO: Loading: mwt\n",
      "2022-06-02 14:05:43 INFO: Loading: sentiment\n",
      "2022-06-02 14:05:44 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> sentence 0 : sentiment: 1\n",
      "Die Wahlverwandtschaften\n",
      "=> sentence 1 : sentiment: 1\n",
      "Ein Roman\n",
      "=> sentence 2 : sentiment: 1\n",
      "von Johann Wolfgang von Goethe\n",
      "=> sentence 3 : sentiment: 1\n",
      "Erster Teil\n",
      "=> sentence 4 : sentiment: 1\n",
      "Erstes Kapitel\n",
      "=> sentence 5 : sentiment: 1\n",
      "Eduard—so nennen wir einen reichen Baron in dem besten Mannesalter — Eduard hatte in seiner Baumschule die schönste Stunde eines Aprilnachmittags zugebracht , um frisch erhaltene Pfropfreiser auf junge Stämme zu bringen .\n",
      "=> sentence 6 : sentiment: 0\n",
      "Sein Geschäft war eben vollendet ;\n",
      "=> sentence 7 : sentiment: 1\n",
      "er legte die Gerätschaften in das Futteral zusammen und betrachtete seine Arbeit mit Vergnügen , als der Gärtner hinzutrat und sich an dem teilnehmenden Fleiße des Herrn ergetzte .\n",
      "=> sentence 8 : sentiment: 1\n",
      "„ Hast du meine Frau nicht gesehen ? “ fragte Eduard , indem er sich weiterzugehen anschickte .\n",
      "=> sentence 9 : sentiment: 1\n",
      "„ Drüben in den neuen Anlagen “ , versetzte der Gärtner .\n",
      "=> sentence 10 : sentiment: 1\n",
      "„ Die Mooshütte wird heute fertig , die sie an der Felswand , dem Schlosse gegenüber , gebaut hat .\n",
      "=> sentence 11 : sentiment: 2\n",
      "Alles ist recht schön geworden und muß Euer Gnaden gefallen .\n",
      "=> sentence 12 : sentiment: 1\n",
      "Man hat einen vortrefflichen Anblick : unten das Dorf , ein wenig rechter Hand die Kirche , über deren Turmspitze man fast hinwegsieht , gegenüber das Schloß und die Gär\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='de', processors='tokenize,sentiment')\n",
    "doc = nlp(text[0:1000])\n",
    "\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print('=> sentence',i, ': sentiment:', sentence.sentiment)\n",
    "    print(*[f'{word.text}' for word in sentence.words], sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c: NER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 14:05:45 WARNING: Language de package default expects mwt, which has been added\n",
      "2022-06-02 14:05:45 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| ner       | conll03 |\n",
      "=======================\n",
      "\n",
      "2022-06-02 14:05:45 INFO: Use device: cpu\n",
      "2022-06-02 14:05:45 INFO: Loading: tokenize\n",
      "2022-06-02 14:05:45 INFO: Loading: mwt\n",
      "2022-06-02 14:05:45 INFO: Loading: ner\n",
      "2022-06-02 14:05:46 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Johann Wolfgang von Goethe\ttype: PER\n",
      "entity: Eduard—so\ttype: PER\n",
      "entity: Eduard\ttype: PER\n",
      "entity: Eduard\ttype: PER\n",
      "entity: Eduard\ttype: PER\n",
      "entity: Eduard\ttype: PER\n",
      "entity: Eduard\ttype: PER\n",
      "entity: Mooshütte\ttype: LOC\n",
      "entity: Charlotte\ttype: PER\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='de', processors='tokenize,ner')\n",
    "doc = nlp(text[0:2500])\n",
    "\n",
    "# sentence based NER output\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for ent in doc.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d: Dependencies:\n",
    "\n",
    "##### Inklusive Transformation in CONLL-Format für Plotting mit NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 14:05:48 WARNING: Language de package default expects mwt, which has been added\n",
      "2022-06-02 14:05:48 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "=======================\n",
      "\n",
      "2022-06-02 14:05:48 INFO: Use device: cpu\n",
      "2022-06-02 14:05:48 INFO: Loading: tokenize\n",
      "2022-06-02 14:05:48 INFO: Loading: mwt\n",
      "2022-06-02 14:05:48 INFO: Loading: pos\n",
      "2022-06-02 14:05:48 INFO: Loading: lemma\n",
      "2022-06-02 14:05:48 INFO: Loading: depparse\n",
      "2022-06-02 14:05:49 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='de', processors='tokenize,pos,lemma,depparse')\n",
    "doc = nlp(text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\n",
       "   {\n",
       "     \"id\": 1,\n",
       "     \"text\": \"Die\",\n",
       "     \"lemma\": \"der\",\n",
       "     \"upos\": \"DET\",\n",
       "     \"xpos\": \"ART\",\n",
       "     \"feats\": \"Case=Nom|Definite=Def|Gender=Fem|Number=Plur|PronType=Art\",\n",
       "     \"head\": 2,\n",
       "     \"deprel\": \"det\",\n",
       "     \"start_char\": 0,\n",
       "     \"end_char\": 3\n",
       "   },\n",
       "   {\n",
       "     \"id\": 2,\n",
       "     \"text\": \"Wahlverwandtschaften\",\n",
       "     \"lemma\": \"Wahlverwandtschaft\",\n",
       "     \"upos\": \"NOUN\",\n",
       "     \"xpos\": \"NN\",\n",
       "     \"feats\": \"Case=Nom|Gender=Fem|Number=Plur\",\n",
       "     \"head\": 0,\n",
       "     \"deprel\": \"root\",\n",
       "     \"start_char\": 4,\n",
       "     \"end_char\": 24\n",
       "   }\n",
       " ]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: „\thead id: 7\thead: gesehen\tdeprel: punct\n",
      "id: 2\tword: Hast\thead id: 7\thead: gesehen\tdeprel: aux\n",
      "id: 3\tword: du\thead id: 7\thead: gesehen\tdeprel: nsubj\n",
      "id: 4\tword: meine\thead id: 5\thead: Frau\tdeprel: det:poss\n",
      "id: 5\tword: Frau\thead id: 7\thead: gesehen\tdeprel: obj\n",
      "id: 6\tword: nicht\thead id: 7\thead: gesehen\tdeprel: advmod\n",
      "id: 7\tword: gesehen\thead id: 10\thead: fragte\tdeprel: ccomp\n",
      "id: 8\tword: ?\thead id: 7\thead: gesehen\tdeprel: punct\n",
      "id: 9\tword: “\thead id: 7\thead: gesehen\tdeprel: punct\n",
      "id: 10\tword: fragte\thead id: 0\thead: root\tdeprel: root\n",
      "id: 11\tword: Eduard\thead id: 10\thead: fragte\tdeprel: nsubj\n",
      "id: 12\tword: ,\thead id: 17\thead: anschickte\tdeprel: punct\n",
      "id: 13\tword: indem\thead id: 17\thead: anschickte\tdeprel: mark\n",
      "id: 14\tword: er\thead id: 17\thead: anschickte\tdeprel: nsubj\n",
      "id: 15\tword: sich\thead id: 17\thead: anschickte\tdeprel: obj\n",
      "id: 16\tword: weiterzugehen\thead id: 17\thead: anschickte\tdeprel: xcomp\n",
      "id: 17\tword: anschickte\thead id: 10\thead: fragte\tdeprel: advcl\n",
      "id: 18\tword: .\thead id: 10\thead: fragte\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences[8:9] for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '„', '\"', 'PUNCT', '$(', '_', '7', 'punct', '_', 'start_char=533|end_char=534'], ['2', 'Hast', 'haben', 'AUX', 'VAFIN', 'Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin', '7', 'aux', '_', 'start_char=534|end_char=538'], ['3', 'du', 'du', 'PRON', 'PPER', 'Case=Nom|Number=Sing|Person=2|PronType=Prs', '7', 'nsubj', '_', 'start_char=539|end_char=541'], ['4', 'meine', 'mein', 'DET', 'PPOSAT', 'Case=Acc|Gender=Fem|Number=Sing|Number[psor]=Sing|Person=1|Poss=Yes|PronType=Prs', '5', 'det:poss', '_', 'start_char=542|end_char=547'], ['5', 'Frau', 'Frau', 'NOUN', 'NN', 'Case=Acc|Gender=Fem|Number=Sing', '7', 'obj', '_', 'start_char=548|end_char=552'], ['6', 'nicht', 'nicht', 'PART', 'PTKNEG', 'Polarity=Neg', '7', 'advmod', '_', 'start_char=553|end_char=558'], ['7', 'gesehen', 'sehen', 'VERB', 'VVPP', 'VerbForm=Part', '10', 'ccomp', '_', 'start_char=559|end_char=566'], ['8', '?', '?', 'PUNCT', '$.', '_', '7', 'punct', '_', 'start_char=566|end_char=567'], ['9', '“', '\"', 'PUNCT', '$(', '_', '7', 'punct', '_', 'start_char=567|end_char=568'], ['10', 'fragte', 'fragen', 'VERB', 'VVFIN', 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin', '0', 'root', '_', 'start_char=569|end_char=575'], ['11', 'Eduard', 'Eduard', 'PROPN', 'NE', 'Case=Nom|Gender=Masc|Number=Sing', '10', 'nsubj', '_', 'start_char=576|end_char=582'], ['12', ',', ',', 'PUNCT', '$,', '_', '17', 'punct', '_', 'start_char=582|end_char=583'], ['13', 'indem', 'indem', 'SCONJ', 'KOUS', '_', '17', 'mark', '_', 'start_char=584|end_char=589'], ['14', 'er', 'er', 'PRON', 'PPER', 'Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs', '17', 'nsubj', '_', 'start_char=590|end_char=592'], ['15', 'sich', 'er|es|sie', 'PRON', 'PRF', 'Case=Acc|Number=Sing|Person=3|PronType=Prs|Reflex=Yes', '17', 'obj', '_', 'start_char=593|end_char=597'], ['16', 'weiterzugehen', 'weiterzugehen', 'VERB', 'VVIZU', 'VerbForm=Inf', '17', 'xcomp', '_', 'start_char=598|end_char=611'], ['17', 'anschickte', 'anschicken', 'VERB', 'VVFIN', 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin', '10', 'advcl', '_', 'start_char=612|end_char=622'], ['18', '.', '.', 'PUNCT', '$.', '_', '10', 'punct', '_', 'start_char=622|end_char=623']]\n"
     ]
    }
   ],
   "source": [
    "dicts = doc.to_dict() # dicts is List[List[Dict]], representing each token / word in each sentence in the document\n",
    "#dicts[0]\n",
    "\n",
    "from stanza.utils.conll import CoNLL\n",
    "conll = CoNLL.convert_dict(dicts) # conll is List[List[List]], representing each token / word in each sentence in the document\n",
    "print(conll[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\t„\\t\"\\tPUNCT\\t$(\\t_\\t7\\tpunct\\t_\\tstart_char=533|end_char=534\\n2\\tHast\\thaben\\tAUX\\tVAFIN\\tMood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\\t7\\taux\\t_\\tstart_char=534|end_char=538\\n3\\tdu\\tdu\\tPRON\\tPPER\\tCase=Nom|Number=Sing|Person=2|PronType=Prs\\t7\\tnsubj\\t_\\tstart_char=539|end_char=541\\n4\\tmeine\\tmein\\tDET\\tPPOSAT\\tCase=Acc|Gender=Fem|Number=Sing|Number[psor]=Sing|Person=1|Poss=Yes|PronType=Prs\\t5\\tdet:poss\\t_\\tstart_char=542|end_char=547\\n5\\tFrau\\tFrau\\tNOUN\\tNN\\tCase=Acc|Gender=Fem|Number=Sing\\t7\\tobj\\t_\\tstart_char=548|end_char=552\\n6\\tnicht\\tnicht\\tPART\\tPTKNEG\\tPolarity=Neg\\t7\\tadvmod\\t_\\tstart_char=553|end_char=558\\n7\\tgesehen\\tsehen\\tVERB\\tVVPP\\tVerbForm=Part\\t10\\tccomp\\t_\\tstart_char=559|end_char=566\\n8\\t?\\t?\\tPUNCT\\t$.\\t_\\t7\\tpunct\\t_\\tstart_char=566|end_char=567\\n9\\t“\\t\"\\tPUNCT\\t$(\\t_\\t7\\tpunct\\t_\\tstart_char=567|end_char=568\\n10\\tfragte\\tfragen\\tVERB\\tVVFIN\\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\\t0\\troot\\t_\\tstart_char=569|end_char=575\\n11\\tEduard\\tEduard\\tPROPN\\tNE\\tCase=Nom|Gender=Masc|Number=Sing\\t10\\tnsubj\\t_\\tstart_char=576|end_char=582\\n12\\t,\\t,\\tPUNCT\\t$,\\t_\\t17\\tpunct\\t_\\tstart_char=582|end_char=583\\n13\\tindem\\tindem\\tSCONJ\\tKOUS\\t_\\t17\\tmark\\t_\\tstart_char=584|end_char=589\\n14\\ter\\ter\\tPRON\\tPPER\\tCase=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs\\t17\\tnsubj\\t_\\tstart_char=590|end_char=592\\n15\\tsich\\ter|es|sie\\tPRON\\tPRF\\tCase=Acc|Number=Sing|Person=3|PronType=Prs|Reflex=Yes\\t17\\tobj\\t_\\tstart_char=593|end_char=597\\n16\\tweiterzugehen\\tweiterzugehen\\tVERB\\tVVIZU\\tVerbForm=Inf\\t17\\txcomp\\t_\\tstart_char=598|end_char=611\\n17\\tanschickte\\tanschicken\\tVERB\\tVVFIN\\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\\t10\\tadvcl\\t_\\tstart_char=612|end_char=622\\n18\\t.\\t.\\tPUNCT\\t$.\\t_\\t10\\tpunct\\t_\\tstart_char=622|end_char=623'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_string = '\\n'.join(['\\t'.join(x) for x in conll[8]])\n",
    "tree_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/nltk/parse/dependencygraph.py:378: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  \"The graph doesn't contain a node \"\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"986pt\" height=\"388pt\"\n",
       " viewBox=\"0.00 0.00 986.22 388.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 384)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-384 982.2227,-384 982.2227,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"628\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"628\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (fragte)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;10 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M628,-343.7616C628,-332.3597 628,-317.4342 628,-304.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"631.5001,-304.2121 628,-294.2121 624.5001,-304.2121 631.5001,-304.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"639.2759\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"316\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (gesehen)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;7 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>10&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M590.0546,-265.5407C533.943,-250.074 428.7584,-221.0808 366.2866,-203.861\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"367.2116,-200.4855 356.641,-201.2023 365.3514,-207.2339 367.2116,-200.4855\"/>\n",
       "<text text-anchor=\"middle\" x=\"509.6587\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ccomp</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"573\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">11 (Eduard)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M615.4605,-257.7903C611.6213,-252.1253 607.4209,-245.8348 603.6621,-240 598.9317,-232.6568 593.9286,-224.6208 589.3668,-217.1807\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"592.0703,-214.891 583.8783,-208.1723 586.0925,-218.5332 592.0703,-214.891\"/>\n",
       "<text text-anchor=\"middle\" x=\"619.1689\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"683\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">17 (anschickte)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;17 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M639.6641,-257.7616C647.2477,-245.9036 657.2686,-230.2345 665.7639,-216.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"668.9135,-218.5223 671.3527,-208.2121 663.0163,-214.7509 668.9135,-218.5223\"/>\n",
       "<text text-anchor=\"middle\" x=\"674.1587\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advcl</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"779\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18 (.)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;18 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>10&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M661.1416,-257.8187C671.3808,-252.1548 682.6785,-245.8578 693,-240 709.5738,-230.5937 727.8377,-220.0068 743.2555,-211.0047\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"745.1047,-213.9779 751.9701,-205.9084 741.5709,-207.9353 745.1047,-213.9779\"/>\n",
       "<text text-anchor=\"middle\" x=\"732.5518\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">punct</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 („)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (Hast)</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"179\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (du)</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"255\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (meine)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"255\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (Frau)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M255,-85.7616C255,-74.3597 255,-59.4342 255,-46.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"258.5001,-46.2121 255,-36.2121 251.5001,-46.2121 258.5001,-46.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"277.9448\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det:poss</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"336\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (nicht)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>7&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M275.3349,-184.0909C239.063,-178.2663 184.7608,-168.1762 138.8965,-154 106.654,-144.0342 97.6192,-138.2543 63.3279,-122.0936\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"64.5775,-118.8144 54.036,-117.7525 61.6145,-125.1564 64.5775,-118.8144\"/>\n",
       "<text text-anchor=\"middle\" x=\"154.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">punct</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>7&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M275.3486,-178.3751C254.0681,-171.9063 227.7344,-163.2946 204.7861,-154 184.0238,-145.5908 161.6111,-134.7799 143.1161,-125.3633\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"144.5978,-122.1896 134.1043,-120.7281 141.3961,-128.4145 144.5978,-122.1896\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.1069\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">aux</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;3 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>7&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M279.2764,-171.8987C268.8833,-166.4434 257.6782,-160.2396 247.6621,-154 235.0725,-146.1572 221.7761,-136.7585 210.2718,-128.2372\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"212.3482,-125.4196 202.2473,-122.2223 208.1497,-131.0208 212.3482,-125.4196\"/>\n",
       "<text text-anchor=\"middle\" x=\"263.1689\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;5 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M303.0635,-171.7616C294.5717,-159.7896 283.3244,-143.9328 273.8451,-130.5685\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"276.5581,-128.3437 267.9179,-122.2121 270.8486,-132.3935 276.5581,-128.3437\"/>\n",
       "<text text-anchor=\"middle\" x=\"298.9448\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">obj</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M320.2415,-171.7616C322.9196,-160.2456 326.4336,-145.1353 329.4636,-132.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"332.9084,-132.745 331.7646,-122.2121 326.0904,-131.1594 332.9084,-132.745\"/>\n",
       "<text text-anchor=\"middle\" x=\"350.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"413\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (?)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M352.2317,-171.9467C360.8363,-166.7861 369.6442,-160.716 377,-154 384.4253,-147.2205 391.2514,-138.6784 396.9172,-130.5821\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.9522,-132.3392 402.5833,-122.0763 394.1264,-128.4584 399.9522,-132.3392\"/>\n",
       "<text text-anchor=\"middle\" x=\"405.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">punct</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"485\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (“)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;9 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>7&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M356.5976,-180.5091C377.7808,-174.6035 403.6564,-165.8511 425,-154 437.1603,-147.248 449.2088,-137.8791 459.2828,-129.0746\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"461.8256,-131.4943 466.903,-122.1953 457.1349,-126.2984 461.8256,-131.4943\"/>\n",
       "<text text-anchor=\"middle\" x=\"460.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">punct</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12 (,)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;12 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>17&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M652.8497,-171.9529C643.7685,-166.3481 633.8411,-160.0503 624.8965,-154 612.915,-145.8955 600.0673,-136.5982 588.8071,-128.2363\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"590.6512,-125.2449 580.5465,-122.0595 586.4593,-130.851 590.6512,-125.2449\"/>\n",
       "<text text-anchor=\"middle\" x=\"640.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">punct</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"641\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">13 (indem)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;13 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>17&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M674.0929,-171.7616C668.3574,-160.0176 660.7964,-144.5355 654.3496,-131.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"657.4277,-129.6618 649.8943,-122.2121 651.1377,-132.7337 657.4277,-129.6618\"/>\n",
       "<text text-anchor=\"middle\" x=\"679.3828\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"725\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">14 (er)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;14 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>17&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M691.9071,-171.7616C697.6426,-160.0176 705.2036,-144.5355 711.6504,-131.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"714.8623,-132.7337 716.1057,-122.2121 708.5723,-129.6618 714.8623,-132.7337\"/>\n",
       "<text text-anchor=\"middle\" x=\"722.1689\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"803\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">15 (sich)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;15 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>17&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M713.8614,-171.8201C722.7663,-166.3143 732.3975,-160.1035 741,-154 752.1235,-146.1078 763.8792,-136.8748 774.1286,-128.5059\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"776.5004,-131.0865 781.9846,-122.0215 772.0444,-125.6879 776.5004,-131.0865\"/>\n",
       "<text text-anchor=\"middle\" x=\"767.9448\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">obj</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"916\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">16 (weiterzugehen)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;16 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M732.1109,-171.9883C747.7414,-166.248 765.0998,-159.8649 781,-154 806.1436,-144.7256 833.9084,-134.4485 857.6875,-125.6358\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"859.1118,-128.8406 867.2719,-122.083 856.6788,-122.277 859.1118,-128.8406\"/>\n",
       "<text text-anchor=\"middle\" x=\"838.0518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">xcomp</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<DependencyGraph with 19 nodes>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import DependencyGraph\n",
    "t = DependencyGraph(tree_string)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3 (Weiterverarbeitung Korpusannotation)\n",
    "\n",
    "Führen Sie auf dem Wahlverwandschaften-Text mit stanza ein POS-Tagging aus und verwenden Sie die Ausgabe für eine POS-Frequenzzählung und Plotting der Ergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 14:05:49 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "=======================\n",
      "\n",
      "2022-06-02 14:05:49 INFO: Use device: cpu\n",
      "2022-06-02 14:05:49 INFO: Loading: tokenize\n",
      "2022-06-02 14:05:49 INFO: Loading: mwt\n",
      "2022-06-02 14:05:49 INFO: Loading: pos\n",
      "2022-06-02 14:05:50 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "text = open('wahlverwandschaften.txt').read()\n",
    "nlp = stanza.Pipeline(lang='de', processors='tokenize, mwt, pos')\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "   \"id\": 1,\n",
       "   \"text\": \"Die\",\n",
       "   \"upos\": \"DET\",\n",
       "   \"xpos\": \"ART\",\n",
       "   \"feats\": \"Case=Nom|Definite=Def|Gender=Fem|Number=Plur|PronType=Art\",\n",
       "   \"start_char\": 0,\n",
       "   \"end_char\": 3\n",
       " }, {\n",
       "   \"id\": 2,\n",
       "   \"text\": \"Wahlverwandtschaften\",\n",
       "   \"upos\": \"NOUN\",\n",
       "   \"xpos\": \"NN\",\n",
       "   \"feats\": \"Case=Nom|Gender=Fem|Number=Plur\",\n",
       "   \"start_char\": 4,\n",
       "   \"end_char\": 24\n",
       " }]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0].words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Die', 'DET'),\n",
       " ('Wahlverwandtschaften', 'NOUN'),\n",
       " ('Ein', 'DET'),\n",
       " ('Roman', 'NOUN'),\n",
       " ('von', 'ADP')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text = [(word.text,word.upos) for sent in doc.sentences for word in sent.words]\n",
    "tagged_text[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pos_count = Counter(tag for _, tag in tagged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DET', 'NOUN', 'ADP', 'PROPN', 'ADJ', 'VERB', 'PRON', 'PUNCT', 'AUX', 'PART', 'ADV', 'CCONJ', 'SCONJ', 'NUM'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_count.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1179, 1728, 919, 185, 878, 1476, 1854, 2331, 608, 277, 1297, 434, 313, 11])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_count.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAEyCAYAAABdxWyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13632f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "height = pos_count.values()\n",
    "bars = pos_count.keys()\n",
    "\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "# Create bars\n",
    "plt.bar(y_pos, height)\n",
    "\n",
    "# Create names on the x-axis\n",
    "plt.xticks(y_pos, bars)\n",
    "\n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PUNCT', 2331),\n",
       " ('PRON', 1854),\n",
       " ('NOUN', 1728),\n",
       " ('VERB', 1476),\n",
       " ('ADV', 1297),\n",
       " ('DET', 1179),\n",
       " ('ADP', 919),\n",
       " ('ADJ', 878),\n",
       " ('AUX', 608),\n",
       " ('CCONJ', 434),\n",
       " ('SCONJ', 313),\n",
       " ('PART', 277),\n",
       " ('PROPN', 185),\n",
       " ('NUM', 11)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_pos_count = pos_count.most_common()\n",
    "sorted_pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2331, 1854, 1728, 1476, 1297, 1179, 919, 878, 608, 434, 313, 277, 185, 11]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[count for _, count in sorted_pos_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAEyCAYAAABdxWyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13632f240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "height = [count for _, count in sorted_pos_count]\n",
    "bars = [tag for tag, _ in sorted_pos_count]\n",
    "\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "# Create bars\n",
    "plt.bar(y_pos, height)\n",
    "\n",
    "# Create names on the x-axis\n",
    "plt.xticks(y_pos, bars)\n",
    "\n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 4: Tagging mit NLTK\n",
    "\n",
    "Auch NLTK enthält Modelle für Textannotationen. Testen Sie die in den NLTK-Kapiteln 3 und 5 beschriebenen Tagger (**POS, Segmentizer, Stemmer, Lemmatizer**) für das Englische aus (wie man einen POS-Tagger mit NLTK selbst trainiert, um etwa auch auf deutschen Texten POS-Tagging mit NLTK durchzuführen, ist Thema in einer späteren Sitzung).\n",
    "\n",
    "- https://www.nltk.org/book/ch03.html\n",
    "- https://www.nltk.org/book/ch05.html\n",
    "\n",
    "\n",
    "> HINWEIS: NLTK ist nicht primär Annotationstool wie stanza/spacy, sondern eher für Preprocessing und trainieren eigener Modelle geeignet (nur wenige vortrainierte Sprachmodelle in NLTK enthalten).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS-Tagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zb: pos-tagging\n",
    "#from nltk.tokenize import word_tokenize\n",
    "text = nltk.word_tokenize(\"And now for something completely different.\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Die', 'NNP'),\n",
       " ('Wahlverwandtschaften', 'NNP'),\n",
       " ('Ein', 'NNP'),\n",
       " ('Roman', 'NNP'),\n",
       " ('von', 'NNP'),\n",
       " ('Johann', 'NNP'),\n",
       " ('Wolfgang', 'NNP'),\n",
       " ('von', 'NNP'),\n",
       " ('Goethe', 'NNP'),\n",
       " ('Erster', 'NNP')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pos_tag basiert auf englischem Modell, kein sinnvolles Ergbenis z.B. für deutsche Texte):\n",
    "text = nltk.word_tokenize(open('wahlverwandschaften.txt').read())\n",
    "#text[0:10]\n",
    "nltk.pos_tag(text[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('die', 'NN'),\n",
       " ('wahlverwandtschaften', 'WRB'),\n",
       " ('ein', 'JJ'),\n",
       " ('roman', 'NN'),\n",
       " ('von', 'NN'),\n",
       " ('johann', 'NN'),\n",
       " ('wolfgang', 'NN'),\n",
       " ('von', 'IN'),\n",
       " ('goethe', 'NN'),\n",
       " ('erster', 'NN')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Case relevant für POS-Tagging!\n",
    "text = nltk.word_tokenize(open('wahlverwandschaften.txt').read().lower())\n",
    "#text[0:10]\n",
    "nltk.pos_tag(text[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Segmentation:\n",
    "- https://www.nltk.org/book/ch03.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' And now.', 'Something completely different.']\n"
     ]
    }
   ],
   "source": [
    "raw_text = \" And now. Something completely different.\"\n",
    "\n",
    "sents = nltk.sent_tokenize(raw_text)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK-Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['denni', ':', 'listen', ',', 'strang', 'women', 'lie', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'power', 'deriv', 'from', 'a', 'mandat', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcic', 'aquat', 'ceremoni', '.']\n"
     ]
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "print([porter.stem(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['den', ':', 'list', ',', 'strange', 'wom', 'lying', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'bas', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'pow', 'der', 'from', 'a', 'mand', 'from', 'the', 'mass', ',', 'not', 'from', 'som', 'farc', 'aqu', 'ceremony', '.']\n"
     ]
    }
   ],
   "source": [
    "print([lancaster.stem(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK-Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DENNIS', ':', 'Listen', ',', 'strange', 'woman', 'lying', 'in', 'pond', 'distributing', 'sword', 'is', 'no', 'basis', 'for', 'a', 'system', 'of', 'government', '.', 'Supreme', 'executive', 'power', 'derives', 'from', 'a', 'mandate', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony', '.']\n"
     ]
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "print([wnl.lemmatize(t) for t in tokens])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
